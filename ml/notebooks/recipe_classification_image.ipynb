{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe classification using image data\n",
    "\n",
    "In order to try this notebook, you need prepare your own data. <br>\n",
    "Directory structure is assumed as following (category0 or 1 can be replaced with the name of the category).\n",
    "\n",
    "- /work/data/image/\n",
    "  - /train\n",
    "    - /category0/*.jpg\n",
    "    - /category1/*.jpg\n",
    "    - ...\n",
    "  - /test\n",
    "    - /category0/*.jpg\n",
    "    - /category1/*.jpg\n",
    "    - ...\n",
    "\n",
    "\n",
    "We use a pretrained model which is trained by ImageNet data; keras has several pretrained models ( https://github.com/fchollet/deep-learning-models ).\n",
    "\n",
    "Pretrained models are quite useful to construct powerful models for our problems with minimum waste by using fine tuning.\n",
    "\n",
    "Outline:\n",
    "\n",
    "- **1. Prepare dataset**\n",
    "- **2. Construct a fine tuning model**\n",
    "- **3. Load the trained model (to restore the model)**\n",
    "- **4. How can we improve the model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset\n",
    "\n",
    "We assume you have already downloaded the data from the s3 bucket.\n",
    "\n",
    "We use keras ImageDataGenerator which is a data generator with various processing methods.\n",
    "\n",
    "If the data is huge which cannot be loaded onto the memory, the generator is indispensable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/work/data/image/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fixed constants for dataset\n",
    "SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Data dirs {train, validation}\n",
    "TRAIN_DATA_DIR = os.path.normpath(os.path.join(DATA_DIR, \"train\"))\n",
    "VALID_DATA_DIR = os.path.normpath(os.path.join(DATA_DIR, \"valid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of ImageDataGenerator: https://keras.io/preprocessing/image/\n",
    "\n",
    "These paramters enable us to do data augmentation which makes a little different training data by using several geometical transformation.\n",
    "\n",
    "Data augmentation is a very important method to acquire the generalization performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        channel_shift_range=0.2,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(\n",
    "        directory=TRAIN_DATA_DIR,\n",
    "        target_size=(SIZE, SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=1729\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many case, we do NOT apply data augmentation to validation dataset because augmentation creates a little different images from original ones, which leads to non-robust validation estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALID_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALID_GENERATOR = VALID_DATAGEN.flow_from_directory(\n",
    "        directory=VALID_DATA_DIR,\n",
    "        target_size=(SIZE, SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=1729\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct a fine tuning model\n",
    "\n",
    "Using the keras InceptionV3 class which was trained on ImageNet dataset, we can easily create a fine tuning model.\n",
    "\n",
    "To build a fine tuning model, the top part of the model should be replaced with a new one that matches our problem.\n",
    "\n",
    "Here we introduce new component.\n",
    "\n",
    "- GlobalAveragePooling <br>\n",
    "  This component performs to take the average over (height, width) for each channel. <br>\n",
    "  Data dimension changes from (batch, height, width, channel) -> (batch, channel) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = \"imagenet\"\n",
    "# BASE_MODEL_NAME = \"/work/notebooks/trained_models/classifier_image\"\n",
    "TRAINED_MODEL_NAME = \"classifier_image\"\n",
    "MODEL_SAVE_PATH = os.path.join(\"/work/notebooks/trained_models/\", TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "def complile_model(base_model_name, only_top=False):\n",
    "    '''\n",
    "    input : \n",
    "        base_model_name - 'imagenet' or model_prefix of your trained model\n",
    "        only_top - if true the model weight except top layers are freezed\n",
    "    return : \n",
    "        compiled model\n",
    "    '''\n",
    "    # Load ImageNet trained model as a base model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    \n",
    "    if base_model_name == 'imagenet':\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        predictions = Dense(TRAIN_GENERATOR.num_class, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "    else:\n",
    "        with open(\"{0}.json\".format(base_model_name), 'r') as f:\n",
    "            model_json = json.dumps(json.load(f)) # Need to convert json to str\n",
    "            model = model_from_json(model_json)\n",
    "        with open(\"{0}-labels.json\".format(base_model_name), 'r') as f:\n",
    "            category_dict = json.load(f)\n",
    "            \n",
    "        model.load_weights(\"{0}.hdf5\".format(base_model_name))\n",
    "        model = Model(inputs=model.input, outputs=model.output)\n",
    "    \n",
    "    # Set layers be trainable\n",
    "    if only_top:\n",
    "        for layer in model.layers[:len(base_model.layers)]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[len(base_model.layers):]:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "    \n",
    "    # Model compile\n",
    "    optimizer = optimizers.Adam(lr=0.001, decay=0.01)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use callbacks for better managing the training process; e.g., saving the best val acc model during training, early stopping to avoid overfitting, and so on.\n",
    "\n",
    "This is optional so we do not use callbacks. (please try them if you are interested in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# FILEPATH = MODEL_SAVE_PATH + \"-{epoch:02d}-{val_acc:.3f}.hdf5\"\n",
    "\n",
    "# CHECKPOINT = ModelCheckpoint(\n",
    "#     FILEPATH\n",
    "#     , monitor='val_acc'\n",
    "#     , verbose=1\n",
    "#     , save_best_only=False\n",
    "#     , mode='max'\n",
    "# )\n",
    "\n",
    "# EARLYSTOPPING = EarlyStopping(\n",
    "#     monitor='val_loss'\n",
    "#     , patience=5\n",
    "#     , verbose=1\n",
    "#     , mode='min'\n",
    "# )\n",
    "\n",
    "# CALLBACKS_LIST = [CHECKPOINT, EARLYSTOPPING]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for model training.\n",
    "\n",
    "Be careful about the difference between fit_generator method and fit method (a little bit confusing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    '''\n",
    "    input : \n",
    "        keras model\n",
    "    return : \n",
    "        trained model & tarin history\n",
    "    '''\n",
    "    history = model.fit_generator(\n",
    "        generator=TRAIN_GENERATOR\n",
    "        , steps_per_epoch= TRAIN_GENERATOR.n // BATCH_SIZE # This corresponds to use all images once for each epoch\n",
    "        , epochs=5\n",
    "        , verbose=1\n",
    "        , validation_data=VALID_GENERATOR\n",
    "        , validation_steps=VALID_GENERATOR.n // BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    model.save_weights('{0}.hdf5'.format(MODEL_SAVE_PATH))\n",
    "    with open(\"{0}.json\".format(MODEL_SAVE_PATH), 'w') as f:\n",
    "        json.dump(json.loads(model.to_json()), f) # model.to_json() is a STRING of json\n",
    "    with open(\"{0}-labels.json\".format(MODEL_SAVE_PATH), 'w') as f:\n",
    "        json.dump(TRAIN_GENERATOR.class_indices, f)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL = complile_model(BASE_MODEL_NAME, only_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model, history = train_model(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # plot of loss function\n",
    "    plt.figure(figsize=(13,7))\n",
    "    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    # plot of accuracy\n",
    "    plt.figure(figsize=(13,7))\n",
    "    plt.plot(history.history['acc'],\"o-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_acc'],\"o-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course draw the model architecture; however, InceptionV3 model is too huge to draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG( model_to_dot(model, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we preprocessed data during training, we have to do the same preprocessing when using the model for prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img_arr, size=224):\n",
    "    '''\n",
    "    input : \n",
    "        image as numpy array\n",
    "    return : \n",
    "        preprocessed image numpy array\n",
    "    '''\n",
    "    # Convert grayscale img  to colored one\n",
    "    if len(img_arr.shape) == 2:\n",
    "        img_arr = gray2rgb(img_arr)\n",
    "\n",
    "    height, width, chan = img_arr.shape\n",
    "    \n",
    "    # Crop the square area whose center is the center of the image\n",
    "    centery = height // 2\n",
    "    centerx = width // 2\n",
    "    radius = min((centerx, centery))\n",
    "    img_arr = img_arr[centery-radius:centery+radius, centerx-radius:centerx+radius]\n",
    "    \n",
    "    # Resize the image to the same shape of the model input\n",
    "    img_arr = imresize(img_arr, size=(size, size), interp='bilinear')\n",
    "    \n",
    "    # Convert to float32\n",
    "    img_arr = np.array(img_arr, dtype=np.float32)\n",
    "    \n",
    "    # Rescale and some modification (the weight of the model is assumed this scale !)\n",
    "    img_arr /= 255.\n",
    "    \n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class for treating test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestData(object):\n",
    "    '''\n",
    "    Data preparation for prediction test\n",
    "    '''\n",
    "    def __init__(self, size):\n",
    "        '''\n",
    "        Set image height and width\n",
    "        '''\n",
    "        self.size = size\n",
    "    \n",
    "    def get_data_paths(self,dirs):\n",
    "        '''\n",
    "        Get all of image paths from given dirs (only .jpg so far)\n",
    "        '''\n",
    "        file_paths = []\n",
    "        for elem in glob.glob(\"{}/*\".format(dirs)):\n",
    "            paths = []\n",
    "            for ext in [\"jpg\",\"jpeg\",\"JPG\",\"JPEG\"]:\n",
    "                paths.extend( glob.glob(os.path.normpath(\"{}/*.{}\").format(elem,ext)) )\n",
    "            file_paths.extend(paths)\n",
    "        return file_paths\n",
    "     \n",
    "    def chunked(self, iterable, N):\n",
    "        '''\n",
    "        Create N chunked lists for given list\n",
    "        '''\n",
    "        return [iterable[x:x + N] for x in range(0, len(iterable), N)]\n",
    "    \n",
    "    def preprocess_data(self, file_paths, category_dict):\n",
    "        '''\n",
    "        Preprocess the images from the set file_paths\n",
    "            input : \n",
    "                file_paths list, category_dict as {'name',num}\n",
    "            return : \n",
    "                preprocessed np arrays of the images\n",
    "        '''\n",
    "        test_data = []\n",
    "        test_labels = []\n",
    "        test_paths = []\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            img = imread(file_path)\n",
    "            img = preprocess(img, self.size)\n",
    "            test_data.append(img)\n",
    "\n",
    "            label = file_path.split('/')[-2]\n",
    "            test_labels.append(category_dict[label])\n",
    "            test_paths.append(file_path)\n",
    "            \n",
    "        test_data = np.array(test_data).astype(np.float32)\n",
    "        test_data = test_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "        return test_data, test_labels, test_paths\n",
    "    \n",
    "    def get_N_sample(self, file_paths, N):\n",
    "        '''\n",
    "        Randomly pick up N images from the set file_paths\n",
    "            input : \n",
    "                file_paths, N as number of picking images\n",
    "            return : \n",
    "                picked N file paths\n",
    "        '''\n",
    "        import random\n",
    "        index = random.sample(range(len(file_paths)), N)\n",
    "        samples = [file_paths[i] for i in index]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instansiation of TestData and define the distionary of the target categories.\n",
    "\n",
    "You should set the category dict as a python dictionary: {'category0' : 0, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata = TestData(SIZE)\n",
    "paths = testdata.get_data_paths(\"/work/data/image/valid/\")\n",
    "category_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Get preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data, test_labels, test_paths = testdata.preprocess_data(paths, category_dict)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prediction = model.predict( test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'prediction' : [np.argmax(elem) for elem in prediction]\n",
    "    , 'answer' : test_labels\n",
    "    , 'path' : test_paths\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_cofusion_matrix(result, category_dict):\n",
    "    '''\n",
    "    input : prediction result as a DF and category dictionary\n",
    "    output : plot of confusion matrix\n",
    "    '''\n",
    "    #Compute confusion matrix\n",
    "    conf_arr = confusion_matrix(result['answer'],result['prediction'])\n",
    "    #Get category names in the order of category values\n",
    "    sorted_categories = sorted(category_dict.items(), key=lambda x:x[1])\n",
    "    labels = [ elem[0] for elem in sorted_categories ]\n",
    "    \n",
    "    #Compute normalized confusion matrix for coloring\n",
    "    norm_conf = []\n",
    "    for i in conf_arr:\n",
    "        a = 0\n",
    "        tmp_arr = []\n",
    "        a = sum(i, 0)\n",
    "        for j in i:\n",
    "            tmp_arr.append(float(j)/float(a))\n",
    "        norm_conf.append(tmp_arr)\n",
    "    \n",
    "    #Draw figure\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    fig = plt.figure()\n",
    "    plt.clf()\n",
    "    fig.set_size_inches(20, 10, forward=True)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, interpolation='nearest')\n",
    "\n",
    "    width, height = conf_arr.shape\n",
    "\n",
    "    plt.xticks(range(len(category_dict)), labels, rotation='vertical')\n",
    "    plt.yticks(range(len(category_dict)), labels)\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(conf_arr[x][y]), xy=(y, x), horizontalalignment='center', verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_cofusion_matrix(result,  category_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the misclassified images.\n",
    "\n",
    "The i-th row means the model predictions are i-th categories (images in the 0th row were predicted as gyoza (0th category) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "gs = gridspec.GridSpec(TRAIN_GENERATOR.num_class, 5)\n",
    "gs.update(wspace=0.025, hspace=0.05) # set the spacing between axes. \n",
    "\n",
    "for idx,cat in enumerate(category_dict.keys()):\n",
    "    wrong_answers_list = list( result[ (result['prediction'] == category_dict[cat]) & (result['answer'] != category_dict[cat]) ].index )\n",
    "    num = min([5,len(wrong_answers_list)])\n",
    "    for i in range(num):\n",
    "        ax = plt.subplot(gs[idx,i])\n",
    "        path = result['path'][wrong_answers_list[i]]\n",
    "        plt.imshow( imread(path) ) # plot\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the trained model\n",
    "\n",
    "Here we try to load the trained model. <br>\n",
    "We can restore the model by using the following files.<br>\n",
    "\n",
    "- {model_name}.json <br>\n",
    "  It stores the model structure (network architecture). <br>\n",
    "- {model_name}-labels.json <br>\n",
    "  It stores the label information, category names and corresponding indices. <br>\n",
    "- {model_name}.hdf5 <br>\n",
    "  It stores weights values. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# from tensorflow import reset_default_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "# reset_default_graph()\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_model_name = \"/work/notebooks/trained_models/classifier_image\"\n",
    "\n",
    "# with open(\"{0}.json\".format(base_model_name), 'r') as f:\n",
    "#     model_json = json.dumps(json.load(f)) # Need to convert json to str\n",
    "#     model = model_from_json(model_json)\n",
    "# with open(\"{0}-labels.json\".format(base_model_name), 'r') as f:\n",
    "#     category_dict = json.load(f)\n",
    "\n",
    "# model.load_weights(\"{0}.hdf5\".format(base_model_name))\n",
    "# model = Model(inputs=model.input, outputs=model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the category information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# prediction = model.predict( test_data )\n",
    "# prediction = [ np.argmax(elem) for elem in prediction ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistency check by comparing the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum( prediction == result['prediction'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. How can we improve the model?\n",
    "\n",
    "- Data size is the most important factor\n",
    "- Data cleansing\n",
    "- Mofication of the model\n",
    "- Rethinking problem settings\n",
    "- ...\n",
    "\n",
    "**It requires your creativity!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Please describe your ideas to improve the model performance\n",
    "- Please implement your ideas and check the result\n",
    "- Can you explain what is the inception module?\n",
    "- Can you explain why we can change the shape of the input though we are using fixed trained weights?\n",
    "- Can you explain the differences among inception versions (V1 ~ V4)?\n",
    "- Can you guess why it's difficult to discriminate ramen from pasta?\n",
    "- Can you have any idea to improve the computational efficiency of the finetuning training?\n",
    "- Can you convert the trained model of Keras to the model of tensorflow?\n",
    "- Can you compare the perfomance of the inference of the Keras model with that of the tensorflow (NOT using Keras) one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
